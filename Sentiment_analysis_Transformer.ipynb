{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOdEOblHTkWGoSfWDg9KpNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sleepyMS/Ai-Development-Collection/blob/main/Sentiment_analysis_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##필요한 라이브러리 및 설정"
      ],
      "metadata": {
        "id": "mhS-_xDKq6m-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SegJexr5qgfa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tweepy\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import datetime\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# 트위터 API 설정\n",
        "auth = tweepy.OAuthHandler(\"API_KEY\", \"API_SECRET_KEY\")\n",
        "auth.set_access_token(\"ACCESS_TOKEN\", \"ACCESS_TOKEN_SECRET\")\n",
        "api = tweepy.API(auth)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##실시간 데이터 수집"
      ],
      "metadata": {
        "id": "dsk6AIfbq_zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binance API를 통한 실시간 암호화폐 데이터 수집\n",
        "def get_crypto_data(symbol, interval='1m', limit=100):\n",
        "    url = f'https://api.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit={limit}'\n",
        "    data = requests.get(url).json()\n",
        "    df = pd.DataFrame(data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    return df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
        "\n",
        "# 트위터에서 실시간 데이터 수집\n",
        "def get_tweets(keyword, count=100):\n",
        "    tweets = tweepy.Cursor(api.search_tweets, q=keyword, lang=\"en\").items(count)\n",
        "    tweet_list = [tweet.text for tweet in tweets]\n",
        "    return tweet_list\n",
        "\n",
        "# 예시: 'Bitcoin' 관련 실시간 트윗과 실시간 Binance 데이터 수집\n",
        "tweets = get_tweets('Bitcoin', 100)\n",
        "crypto_data = get_crypto_data('BTCUSDT')"
      ],
      "metadata": {
        "id": "sQdBiv32qzPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터 전처리"
      ],
      "metadata": {
        "id": "RswfQKRLrBjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# 텍스트 전처리 함수 (트윗)\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # URL 제거\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # 특수 문자 제거\n",
        "    text = text.lower()  # 소문자 변환\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # 불용어 제거\n",
        "    return text\n",
        "\n",
        "# 트윗 전처리\n",
        "preprocessed_tweets = [preprocess_text(tweet) for tweet in tweets]\n",
        "\n",
        "# 시계열 데이터 정규화 (암호화폐 데이터)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "crypto_scaled = scaler.fit_transform(crypto_data['close'].values.reshape(-1,1))\n"
      ],
      "metadata": {
        "id": "JypqFiUNq1wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##감정 분석 모델 (BERT)"
      ],
      "metadata": {
        "id": "oG1hZAr8rFwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "# BERT 감정 분석 수행\n",
        "def get_sentiment_scores(texts):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    sentiment_scores = torch.argmax(outputs.logits, dim=-1)\n",
        "    return sentiment_scores.numpy()\n",
        "\n",
        "# 트윗의 감정 분석 결과 얻기\n",
        "sentiment_scores = get_sentiment_scores(preprocessed_tweets)"
      ],
      "metadata": {
        "id": "pDN3xq_1q3C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM 모델 설계"
      ],
      "metadata": {
        "id": "bmLWcX0WQqWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# LSTM 모델 구축\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=50, return_sequences=True, input_shape=(crypto_scaled.shape[1], 1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=50, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units=1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# 학습 데이터를 위한 준비\n",
        "def create_dataset(data, time_step=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)-time_step-1):\n",
        "        X.append(data[i:(i+time_step), 0])\n",
        "        y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# LSTM 모델 학습\n",
        "X_train, y_train = create_dataset(crypto_scaled)\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "lstm_model = build_lstm_model()\n",
        "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "BIJQ59V8Qth_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##하이브리드 모델: LSTM과 BERT 결합"
      ],
      "metadata": {
        "id": "OkeXHWGeQ3o6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 트랜스포머 감정 점수와 LSTM 예측 값 결합\n",
        "def hybrid_model(sentiment_scores, lstm_predictions):\n",
        "    sentiment_scores = sentiment_scores.reshape(-1, 1)\n",
        "    lstm_predictions = lstm_predictions.reshape(-1, 1)\n",
        "    combined_input = np.hstack((sentiment_scores, lstm_predictions))\n",
        "\n",
        "    # 간단한 회귀 모델로 결합된 입력 학습\n",
        "    reg_model = LinearRegression()\n",
        "    reg_model.fit(combined_input, y_train)\n",
        "    return reg_model\n",
        "\n",
        "# LSTM 예측값 생성\n",
        "lstm_predictions = lstm_model.predict(X_train)\n",
        "\n",
        "# 하이브리드 모델 학습\n",
        "hybrid_reg_model = hybrid_model(sentiment_scores[:len(lstm_predictions)], lstm_predictions)\n"
      ],
      "metadata": {
        "id": "orllW-oAQ1_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##성능 평가 및 급등락 확률 계산"
      ],
      "metadata": {
        "id": "pibiQoHTQ6gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# RMSE 및 R2 평가\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return rmse, r2\n",
        "\n",
        "# LSTM 및 하이브리드 모델 평가\n",
        "lstm_rmse, lstm_r2 = evaluate_model(y_train, lstm_predictions)\n",
        "print(f'LSTM RMSE: {lstm_rmse}, R2: {lstm_r2}')\n",
        "\n",
        "# 급등락 확률 계산\n",
        "def calculate_volatility_probability(predictions, threshold=0.2):\n",
        "    z_scores = (predictions - np.mean(predictions)) / np.std(predictions)\n",
        "    return np.mean(z_scores > threshold)\n",
        "\n",
        "volatility_prob = calculate_volatility_probability(lstm_predictions)\n",
        "print(f'급등락 확률: {volatility_prob}')\n"
      ],
      "metadata": {
        "id": "_LHwTpUKQ5-d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}